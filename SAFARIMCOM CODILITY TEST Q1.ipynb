{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "13a9b1ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"THE ERROR IN THIS CODE IS IN THE INVERSE DOCUMENT FREQUENCY.\\nI'VE TRIED VARIOUS IMPLEMENTATION WHICH DON'T SEEM TO WORK\\nCODED BY LAWRENCE\\nDATE: 23/02/2022 \""
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"THE ERROR IN THIS CODE IS IN THE INVERSE DOCUMENT FREQUENCY.\n",
    "I'VE TRIED VARIOUS IMPLEMENTATION WHICH DON'T SEEM TO WORK\n",
    "CODED BY LAWRENCE\n",
    "DATE: 23/02/2022 \"\"\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "89e152e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import nltk\n",
    "import math"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "f9cd1d61",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TFDIF:\n",
    "    def term_frequency(self, term, sentence):\n",
    "        #use nltk.word_tokenize\n",
    "        # convert sentence to lower\n",
    "        # also the term also should be in lower\n",
    "        \n",
    "        # tokenize the sentence we expect a list of terms.\n",
    "        # loop through the list counting how many times the term appears \n",
    "        # in the list\n",
    "        # return the count.\n",
    "        \n",
    "        tokenized = nltk.word_tokenize(sentence.lower())\n",
    "        count = tokenized.count(term.lower())\n",
    "#         print(\"-------TF is okey ---------\")\n",
    "        \n",
    "        if count != 0:\n",
    "            return 0.5 + 0.5 * (count / count)\n",
    "        \n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    \n",
    "    def inverse_document_frequency(self, term, corpus):\n",
    "       # please use nltk.word_tokenize\n",
    "       # already tokenized in the token above\n",
    "       # corpus contain words \n",
    "       # assume the corpus is  a list containing sentences.\n",
    "       # get the no of sentnces in this list\n",
    "       # count how many times the term appears in each sentence.\n",
    "        \n",
    "        frequency = 0\n",
    "        \n",
    "        for i in range(len(corpus)):\n",
    "#             print(i, len(corpus))\n",
    "            sentence = corpus[i]\n",
    "                              \n",
    "                \n",
    "            if term.lower() in sentence.lower():\n",
    "                frequency = frequency + 1\n",
    "#                 print(sentence, frequency)\n",
    "#                   print(frequency)\n",
    "#             else: pass\n",
    "                    \n",
    "        results = math.log( len(corpus) / frequency)\n",
    "#             print(results)\n",
    "#         try:\n",
    "                        \n",
    "        return results\n",
    "#         except: \"term does not occur in the corpus\"\n",
    "    \n",
    "          \n",
    "    def tfidf(self, term, sentence, corpus):\n",
    "        #tfidf is the product of the above two functions\n",
    "        \n",
    "        calcu = self.term_frequency(term, sentence)\n",
    "#         print(\"calc: {}\".format(calc))\n",
    "        inverse = self.inverse_document_frequency(term, corpus)\n",
    "#         print(\"inv: {}\".format(inverse))\n",
    "        return calcu * inverse\n",
    "        \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "022b16a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# a = TFDIF()\n",
    "\n",
    "# what = a.term_frequency(\"happy\", \"I am very happy happy\")\n",
    "# inv = a.inverse_document_frequency(\"happy\",  [\"I was very happy\",\"We were very happy\"])\n",
    "# tfidf = a.tfidf(\"happy\",\"I am very happy happy\", [\"I was very happy\",\"We were very happy\"] )\n",
    "# print(tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e4508aef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "0.0\n",
      "0.0\n"
     ]
    }
   ],
   "source": [
    "corpus = [\"The quick brown fox jumps over the lazy dog\",\"Never jump over the lazy dog quickly\"]\n",
    "term = \"the\"\n",
    "b =TFDIF()\n",
    "res = b.term_frequency(term,corpus[1]);print(res)\n",
    "idf = b.inverse_document_frequency(term,corpus);print(idf)\n",
    "tidf = b.tfidf(\"The\", corpus[1], corpus);print(tidf)\n",
    "# print(\"term_freq : {}\".format(res))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
